{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "FuzzyWuzzy.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hE4lF56j2Nwz",
        "colab_type": "text"
      },
      "source": [
        "## Objectives"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u5AL2ApX2Nw2",
        "colab_type": "text"
      },
      "source": [
        "This notebook implements logistic regression and gradient boosting methods on both basics and fuzzy-wuzzy features of the quora question pairs dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qm7TN-u02Nw3",
        "colab_type": "text"
      },
      "source": [
        "### Installs and imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LRJgaAxc2Nw5",
        "colab_type": "code",
        "outputId": "6b4b0470-e633-4060-c6cf-5eb1892e5eca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "!python -V"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Python 3.6.9\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "zPlOpTbHzR11",
        "colab": {}
      },
      "source": [
        "!pip3 install fuzzywuzzy\n",
        "!pip3 install python-Levenshtein\n",
        "!pip install sentence-transformers"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "1DoLCgUEzODG",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import fuzzywuzzy\n",
        "from fuzzywuzzy import fuzz\n",
        "from sklearn import linear_model\n",
        "from sklearn import metrics\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import xgboost as xgb\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DW8YgvLS3Vvs",
        "colab_type": "code",
        "outputId": "44a1fc62-ee26-44f7-ff26-3d6b23fa24c7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')\n",
        "%cd '/content/drive/My Drive/NLP/'\n",
        "!ls"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive/\n",
            "/content/drive/My Drive/NLP\n",
            "data\t\t   FuzzyWuzzy.ipynb\n",
            "Fuzzy_Quora.ipynb  Sentence_Transformers_embbedings.ipynb\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QqHYq6bv2Nxf",
        "colab_type": "text"
      },
      "source": [
        "### Download data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "0-SZMKt32h_1",
        "outputId": "69ec3a18-27ed-4ff3-8b2b-b9e67650815d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "data_path = \"data/\" #change datapath to fit yours\n",
        "\n",
        "df_train = pd.read_csv(data_path+\"train.csv\")\n",
        "\n",
        "df_train = df_train.dropna()\n",
        "df_train.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "404287"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jhAaKLFP2Nxo",
        "colab_type": "code",
        "outputId": "9f532401-d458-4a6f-e112-0bc6d807f0d8",
        "colab": {}
      },
      "source": [
        "df_train = df_train.drop(['id', 'qid1', 'qid2'], axis=1)\n",
        "df_train[0:10]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>question1</th>\n",
              "      <th>question2</th>\n",
              "      <th>is_duplicate</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>What is the step by step guide to invest in sh...</td>\n",
              "      <td>What is the step by step guide to invest in sh...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>What is the story of Kohinoor (Koh-i-Noor) Dia...</td>\n",
              "      <td>What would happen if the Indian government sto...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>How can I increase the speed of my internet co...</td>\n",
              "      <td>How can Internet speed be increased by hacking...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Why am I mentally very lonely? How can I solve...</td>\n",
              "      <td>Find the remainder when [math]23^{24}[/math] i...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Which one dissolve in water quikly sugar, salt...</td>\n",
              "      <td>Which fish would survive in salt water?</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Astrology: I am a Capricorn Sun Cap moon and c...</td>\n",
              "      <td>I'm a triple Capricorn (Sun, Moon and ascendan...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Should I buy tiago?</td>\n",
              "      <td>What keeps childern active and far from phone ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>How can I be a good geologist?</td>\n",
              "      <td>What should I do to be a great geologist?</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>When do you use シ instead of し?</td>\n",
              "      <td>When do you use \"&amp;\" instead of \"and\"?</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Motorola (company): Can I hack my Charter Moto...</td>\n",
              "      <td>How do I hack Motorola DCX3400 for free internet?</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                           question1  \\\n",
              "0  What is the step by step guide to invest in sh...   \n",
              "1  What is the story of Kohinoor (Koh-i-Noor) Dia...   \n",
              "2  How can I increase the speed of my internet co...   \n",
              "3  Why am I mentally very lonely? How can I solve...   \n",
              "4  Which one dissolve in water quikly sugar, salt...   \n",
              "5  Astrology: I am a Capricorn Sun Cap moon and c...   \n",
              "6                                Should I buy tiago?   \n",
              "7                     How can I be a good geologist?   \n",
              "8                    When do you use シ instead of し?   \n",
              "9  Motorola (company): Can I hack my Charter Moto...   \n",
              "\n",
              "                                           question2  is_duplicate  \n",
              "0  What is the step by step guide to invest in sh...             0  \n",
              "1  What would happen if the Indian government sto...             0  \n",
              "2  How can Internet speed be increased by hacking...             0  \n",
              "3  Find the remainder when [math]23^{24}[/math] i...             0  \n",
              "4            Which fish would survive in salt water?             0  \n",
              "5  I'm a triple Capricorn (Sun, Moon and ascendan...             1  \n",
              "6  What keeps childern active and far from phone ...             0  \n",
              "7          What should I do to be a great geologist?             1  \n",
              "8              When do you use \"&\" instead of \"and\"?             0  \n",
              "9  How do I hack Motorola DCX3400 for free internet?             0  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "IPtU8h4F3M0K",
        "colab": {}
      },
      "source": [
        "df_train[\"question1\"] = df_train[\"question1\"].astype(\"str\")\n",
        "df_train[\"question2\"] = df_train[\"question2\"].astype('str')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "act61as62Nx7",
        "colab_type": "text"
      },
      "source": [
        "## Features 1 : basics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RWgF1g5R2Nx9",
        "colab_type": "text"
      },
      "source": [
        "We first compute basic features from dataset's sentences (lengths, #common words,...)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W_pNe4ne2Nx-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Length of questions\n",
        "df_train['len_q1'] = df_train.question1.apply(lambda x: len(str(x)))\n",
        "df_train['len_q2'] = df_train.question2.apply(lambda x: len(str(x)))\n",
        "# Difference between length of the two questions\n",
        "df_train['diff_len'] = df_train.len_q1 - df_train.len_q2\n",
        "# Character length without spaces\n",
        "df_train['len_char_q1'] = df_train.question1.apply(lambda x: len(''.join(set(str(x).replace(' ', '')))))\n",
        "df_train['len_char_q2'] = df_train.question2.apply(lambda x: len(''.join(set(str(x).replace(' ', '')))))\n",
        "# Number of words\n",
        "df_train['len_word_q1'] = df_train.question1.apply(lambda x: len(str(x).split()))\n",
        "df_train['len_word_q2'] = df_train.question2.apply(lambda x: len(str(x).split()))\n",
        "# Number of common words in the two questions\n",
        "df_train['common_words'] = df_train.apply(lambda x: len(set(str(x['question1'])\n",
        "    .lower().split())\n",
        "    .intersection(set(str(x['question2'])\n",
        "    .lower().split()))), axis=1)\n",
        "\n",
        "basics = ['len_q1', 'len_q2', 'diff_len', 'len_char_q1', 'len_char_q2', 'len_word_q1', 'len_word_q2', 'common_words']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JvNay9hZ2NyE",
        "colab_type": "text"
      },
      "source": [
        "## Features 2 : fuzzy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YCAKvQim2NyG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_train['fuzz_qratio'] = df_train.apply(lambda x: fuzz.QRatio(str(x['question1']), str(x['question2'])), axis=1)\n",
        "\n",
        "df_train['fuzz_WRatio'] = df_train.apply(lambda x: fuzz.WRatio(str(x['question1']), str(x['question2'])), axis=1)\n",
        "\n",
        "df_train['fuzz_partial_ratio'] = df_train.apply(lambda x: fuzz.partial_ratio(\n",
        "    str(x['question1']), str(x['question2'])), axis=1)\n",
        "\n",
        "df_train['fuzz_partial_token_set_ratio'] = df_train.apply(lambda x: fuzz.partial_token_set_ratio(\n",
        "    str(x['question1']), str(x['question2'])), axis=1)\n",
        "\n",
        "df_train['fuzz_partial_token_sort_ratio'] = df_train.apply(lambda x: fuzz.partial_token_sort_ratio(\n",
        "    str(x['question1']), str(x['question2'])), axis=1)\n",
        "\n",
        "df_train['fuzz_token_set_ratio'] = df_train.apply(lambda x: fuzz.token_set_ratio(\n",
        "str(x['question1']), str(x['question2'])), axis=1)\n",
        "\n",
        "df_train['fuzz_token_sort_ratio'] = df_train.apply(lambda x: fuzz.token_sort_ratio(\n",
        "    str(x['question1']), str(x['question2'])), axis=1)\n",
        "\n",
        "fuzzys = ['fuzz_qratio', 'fuzz_WRatio', 'fuzz_partial_ratio', 'fuzz_partial_token_set_ratio',\n",
        "          'fuzz_partial_token_sort_ratio','fuzz_token_set_ratio', 'fuzz_token_sort_ratio']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w_QT4brA2NyL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#df_train.to_pickle('data/df_train_wfs1fs2.plk')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NtWHwisp2Nyq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#df_train = pd.read_pickle('data/df_train_wfs1fs2.plk')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hsdGco3v2Nyo",
        "colab_type": "text"
      },
      "source": [
        "# Preparing datasets for learning methods"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o_NMkzI42Nyp",
        "colab_type": "text"
      },
      "source": [
        "We now train and evaluate **logistic regression** and **gradient boosting** on those features."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "YQU90Tn42Nyv",
        "colab_type": "code",
        "outputId": "fbf4196c-ac5f-4020-fdb1-e5eef6cafd8d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 638
        }
      },
      "source": [
        "df_train[0:5]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>question1</th>\n",
              "      <th>question2</th>\n",
              "      <th>is_duplicate</th>\n",
              "      <th>len_q1</th>\n",
              "      <th>len_q2</th>\n",
              "      <th>diff_len</th>\n",
              "      <th>len_char_q1</th>\n",
              "      <th>len_char_q2</th>\n",
              "      <th>len_word_q1</th>\n",
              "      <th>len_word_q2</th>\n",
              "      <th>common_words</th>\n",
              "      <th>fuzz_qratio</th>\n",
              "      <th>fuzz_WRatio</th>\n",
              "      <th>fuzz_partial_ratio</th>\n",
              "      <th>fuzz_partial_token_set_ratio</th>\n",
              "      <th>fuzz_partial_token_sort_ratio</th>\n",
              "      <th>fuzz_token_set_ratio</th>\n",
              "      <th>fuzz_token_sort_ratio</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>What is the step by step guide to invest in sh...</td>\n",
              "      <td>What is the step by step guide to invest in sh...</td>\n",
              "      <td>0</td>\n",
              "      <td>66</td>\n",
              "      <td>57</td>\n",
              "      <td>9</td>\n",
              "      <td>20</td>\n",
              "      <td>20</td>\n",
              "      <td>14</td>\n",
              "      <td>12</td>\n",
              "      <td>10</td>\n",
              "      <td>93</td>\n",
              "      <td>95</td>\n",
              "      <td>98</td>\n",
              "      <td>100</td>\n",
              "      <td>89</td>\n",
              "      <td>100</td>\n",
              "      <td>93</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>What is the story of Kohinoor (Koh-i-Noor) Dia...</td>\n",
              "      <td>What would happen if the Indian government sto...</td>\n",
              "      <td>0</td>\n",
              "      <td>51</td>\n",
              "      <td>88</td>\n",
              "      <td>-37</td>\n",
              "      <td>21</td>\n",
              "      <td>29</td>\n",
              "      <td>8</td>\n",
              "      <td>13</td>\n",
              "      <td>4</td>\n",
              "      <td>66</td>\n",
              "      <td>86</td>\n",
              "      <td>73</td>\n",
              "      <td>100</td>\n",
              "      <td>75</td>\n",
              "      <td>86</td>\n",
              "      <td>63</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>How can I increase the speed of my internet co...</td>\n",
              "      <td>How can Internet speed be increased by hacking...</td>\n",
              "      <td>0</td>\n",
              "      <td>73</td>\n",
              "      <td>59</td>\n",
              "      <td>14</td>\n",
              "      <td>25</td>\n",
              "      <td>24</td>\n",
              "      <td>14</td>\n",
              "      <td>10</td>\n",
              "      <td>4</td>\n",
              "      <td>54</td>\n",
              "      <td>63</td>\n",
              "      <td>53</td>\n",
              "      <td>100</td>\n",
              "      <td>71</td>\n",
              "      <td>66</td>\n",
              "      <td>66</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Why am I mentally very lonely? How can I solve...</td>\n",
              "      <td>Find the remainder when [math]23^{24}[/math] i...</td>\n",
              "      <td>0</td>\n",
              "      <td>50</td>\n",
              "      <td>65</td>\n",
              "      <td>-15</td>\n",
              "      <td>19</td>\n",
              "      <td>26</td>\n",
              "      <td>11</td>\n",
              "      <td>9</td>\n",
              "      <td>0</td>\n",
              "      <td>35</td>\n",
              "      <td>35</td>\n",
              "      <td>30</td>\n",
              "      <td>37</td>\n",
              "      <td>38</td>\n",
              "      <td>36</td>\n",
              "      <td>36</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Which one dissolve in water quikly sugar, salt...</td>\n",
              "      <td>Which fish would survive in salt water?</td>\n",
              "      <td>0</td>\n",
              "      <td>76</td>\n",
              "      <td>39</td>\n",
              "      <td>37</td>\n",
              "      <td>25</td>\n",
              "      <td>18</td>\n",
              "      <td>13</td>\n",
              "      <td>7</td>\n",
              "      <td>2</td>\n",
              "      <td>46</td>\n",
              "      <td>86</td>\n",
              "      <td>54</td>\n",
              "      <td>100</td>\n",
              "      <td>63</td>\n",
              "      <td>67</td>\n",
              "      <td>47</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                           question1  ... fuzz_token_sort_ratio\n",
              "0  What is the step by step guide to invest in sh...  ...                    93\n",
              "1  What is the story of Kohinoor (Koh-i-Noor) Dia...  ...                    63\n",
              "2  How can I increase the speed of my internet co...  ...                    66\n",
              "3  Why am I mentally very lonely? How can I solve...  ...                    36\n",
              "4  Which one dissolve in water quikly sugar, salt...  ...                    47\n",
              "\n",
              "[5 rows x 18 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FTn1OAqG2Ny0",
        "colab_type": "text"
      },
      "source": [
        "Since logistic regression is sensitive to the scale of the features we will start by standardizing the data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tz_KVFFu2Ny0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "scaler = StandardScaler()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fUc09EOO2Ny5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y = df_train.is_duplicate.values\n",
        "y = y.astype('float32').reshape(-1, 1)\n",
        "X = df_train[basics+fuzzys]\n",
        "X = X.replace([np.inf, -np.inf], np.nan).fillna(0).values\n",
        "X = scaler.fit_transform(X)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3G4uZ6072Ny-",
        "colab_type": "text"
      },
      "source": [
        " Then we separate data in 80(training)-20(validation) sets for validation purposes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w4JHFve82Ny_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.random.seed(42)\n",
        "\n",
        "#shuffling data to avoid bias\n",
        "total = y.shape[0]\n",
        "index = np.arange(total) \n",
        "np.random.shuffle(index)\n",
        "\n",
        "#we split the dataset into 20% val - 80% train\n",
        "split = 2*total // 10 \n",
        "index_val = index[:split]\n",
        "index_train = index[split:]\n",
        "\n",
        "x_train = X[index_train]\n",
        "y_train = np.ravel(y[index_train])\n",
        "x_val = X[index_val]\n",
        "y_val = np.ravel(y[index_val])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GgLvzzbf2NzE",
        "colab_type": "code",
        "outputId": "46c95e04-e83f-469d-fb49-d895c08a9a3b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "print(\"x_train shape is: {}\".format(x_train.shape) + \" and x_val shape is: {}\".format(x_val.shape))\n",
        "print(\"y_train shape is: {}\".format(y_train.shape) + \" and y_val shape is: {}\".format(y_val.shape))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x_train shape is: (323430, 15) and x_val shape is: (80857, 15)\n",
            "y_train shape is: (323430,) and y_val shape is: (80857,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0UixYTEU2NzI",
        "colab_type": "text"
      },
      "source": [
        "# Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PlAgSpkq2NzJ",
        "colab_type": "code",
        "outputId": "b761d9fe-c5ec-40e8-b64a-c265bad09030",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 555
        }
      },
      "source": [
        "#we run a logistic regression with SGD classifier on training data\n",
        "lreg = linear_model.SGDClassifier(loss='log',verbose=1)\n",
        "lreg.fit(x_train, y_train)\n",
        "\n",
        "#then compute predictions on validation set\n",
        "lreg_preds_prob = lreg.predict_proba(x_val)\n",
        "lreg_preds = lreg.predict(x_val)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-- Epoch 1\n",
            "Norm: 1.87, NNZs: 15, Bias: -1.042574, T: 323430, Avg. loss: 0.826222\n",
            "Total training time: 0.09 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.64, NNZs: 15, Bias: -0.881555, T: 646860, Avg. loss: 0.567772\n",
            "Total training time: 0.18 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.74, NNZs: 15, Bias: -0.999070, T: 970290, Avg. loss: 0.562243\n",
            "Total training time: 0.27 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.72, NNZs: 15, Bias: -0.941560, T: 1293720, Avg. loss: 0.560219\n",
            "Total training time: 0.37 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.76, NNZs: 15, Bias: -0.877275, T: 1617150, Avg. loss: 0.559130\n",
            "Total training time: 0.46 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.76, NNZs: 15, Bias: -0.885203, T: 1940580, Avg. loss: 0.558451\n",
            "Total training time: 0.55 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 1.71, NNZs: 15, Bias: -1.049317, T: 2264010, Avg. loss: 0.557926\n",
            "Total training time: 0.65 seconds.\n",
            "-- Epoch 8\n",
            "Norm: 1.72, NNZs: 15, Bias: -0.941282, T: 2587440, Avg. loss: 0.557599\n",
            "Total training time: 0.74 seconds.\n",
            "-- Epoch 9\n",
            "Norm: 1.67, NNZs: 15, Bias: -0.921736, T: 2910870, Avg. loss: 0.557276\n",
            "Total training time: 0.83 seconds.\n",
            "-- Epoch 10\n",
            "Norm: 1.70, NNZs: 15, Bias: -0.923803, T: 3234300, Avg. loss: 0.557078\n",
            "Total training time: 0.93 seconds.\n",
            "Convergence after 10 epochs took 0.93 seconds\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8fH7GFIWxvvk",
        "colab_type": "code",
        "outputId": "c1e82539-3e13-45ea-bc53-2487f1df9459",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "###### ###### ######      RESULTS     ###### ###### ###### \n",
        "\n",
        "lreg_accuracy = metrics.accuracy_score(y_val,lreg_preds)\n",
        "lreg_f1 = metrics.f1_score(y_val,lreg_preds)\n",
        "lreg_loss = metrics.log_loss(y_val,lreg_preds_prob)\n",
        "\n",
        "print(\"Logistic regression accuracy on validation set: %0.3f\" % lreg_accuracy)\n",
        "print(\"Logistic regression F1score on validation set: %0.3f\" % lreg_f1)\n",
        "print(\"Logistic regression loss on validation set: %0.3f\" % lreg_loss)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Logistic regression accuracy on validation set: 0.663\n",
            "Logistic regression F1score on validation set: 0.501\n",
            "Logistic regression loss on validation set: 0.555\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q79u4_t_2NzP",
        "colab_type": "text"
      },
      "source": [
        "# Gradient Boosting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H4P6aLQo2NzQ",
        "colab_type": "code",
        "outputId": "c25c9972-df22-4ab0-f2f3-e98ec5e47929",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 243
        }
      },
      "source": [
        "#we run a gradient boosting binary classification on training data\n",
        "params = dict()\n",
        "params['objective'] = 'binary:logistic'\n",
        "params['loss'] = ['logloss']\n",
        "params['learning_rate'] = 0.02\n",
        "params['max_depth'] = 4\n",
        "params['eval_metric'] = ['logloss', 'error']\n",
        "\n",
        "d_train = xgb.DMatrix(x_train, label=y_train)\n",
        "d_valid = xgb.DMatrix(x_val, label=y_val)\n",
        "watchlist = [(d_train, 'train'), (d_valid, 'valid')]\n",
        "\n",
        "boosting = xgb.train(params, d_train, 5000, watchlist, early_stopping_rounds=20, verbose_eval=100)\n",
        "xgboost_preds = (boosting.predict(d_valid) >= 0.5).astype(int)\n",
        "xgboost_preds_proba = (boosting.predict(d_valid)).astype(float)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0]\ttrain-logloss:0.687866\ttrain-error:0.305504\tvalid-logloss:0.687854\tvalid-error:0.304612\n",
            "Multiple eval metrics have been passed: 'valid-error' will be used for early stopping.\n",
            "\n",
            "Will train until valid-error hasn't improved in 20 rounds.\n",
            "[100]\ttrain-logloss:0.526235\ttrain-error:0.296398\tvalid-logloss:0.526048\tvalid-error:0.293902\n",
            "[200]\ttrain-logloss:0.507651\ttrain-error:0.291896\tvalid-logloss:0.507794\tvalid-error:0.289746\n",
            "[300]\ttrain-logloss:0.501285\ttrain-error:0.288072\tvalid-logloss:0.501693\tvalid-error:0.286827\n",
            "[400]\ttrain-logloss:0.496418\ttrain-error:0.284952\tvalid-logloss:0.49717\tvalid-error:0.283884\n",
            "[500]\ttrain-logloss:0.492666\ttrain-error:0.281424\tvalid-logloss:0.493887\tvalid-error:0.280928\n",
            "[600]\ttrain-logloss:0.489615\ttrain-error:0.279421\tvalid-logloss:0.491166\tvalid-error:0.278578\n",
            "Stopping. Best iteration:\n",
            "[600]\ttrain-logloss:0.489615\ttrain-error:0.279421\tvalid-logloss:0.491166\tvalid-error:0.278578\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fLJWWNKQGvAT",
        "colab_type": "code",
        "outputId": "bf33fc75-4075-4a53-8858-998aff201c56",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "###### ###### ######      RESULTS     ###### ###### ###### \n",
        "\n",
        "xgboost_accuracy = metrics.accuracy_score(y_val,xgboost_preds)\n",
        "xgboost_f1 = metrics.f1_score(y_val,xgboost_preds)\n",
        "xgboost_loss = metrics.log_loss(y_val,xgboost_preds_proba)\n",
        "print(\"Gradient boosting accuracy on validation set: %0.3f\" % xgboost_accuracy)\n",
        "print(\"Gradient boosting F1score on validation set: %0.3f\" % xgboost_f1)\n",
        "print(\"Gradient boosting loss on validation set: %0.3f\" % xgboost_loss)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Gradient boosting accuracy on validation set: 0.721\n",
            "Gradient boosting F1score on validation set: 0.657\n",
            "Gradient boosting loss on validation set: 0.491\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}
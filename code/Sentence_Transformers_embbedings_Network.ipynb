{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Sentence_Transformers_embbedings_Network.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "8UDvvXg-y_zV",
        "colab_type": "code",
        "outputId": "81452235-baf8-4e30-c426-18985ffff13a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        }
      },
      "source": [
        "#Connect to our own Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4iVs-IpLg8_I",
        "colab_type": "text"
      },
      "source": [
        "https://pypi.org/project/sentence-transformers/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5_RPgP56zCky",
        "colab_type": "code",
        "outputId": "160d801d-d04e-4434-b8a0-e99629ba856f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "%cd \"/content/gdrive/My Drive/ProjetNLPQuora/\"\n",
        "!ls"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/My Drive/ProjetNLPQuora\n",
            "bert-master  test.csv  train.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1DoLCgUEzODG",
        "colab_type": "code",
        "outputId": "d36f1799-4716-441c-b8ab-3707622690e4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "from numpy import genfromtxt\n",
        "\n",
        "\n",
        "\n",
        "df_train = pd.read_csv(\"train.csv\")\n",
        "df_test = pd.read_csv(\"test.csv\")\n",
        "\n",
        "#embq1 = genfromtxt('embq1.csv', delimiter=',')\n",
        "#embq2 = genfromtxt('embq2.csv', delimiter=',')\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2718: DtypeWarning: Columns (0) have mixed types.Specify dtype option on import or set low_memory=False.\n",
            "  interactivity=interactivity, compiler=compiler, result=result)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0-SZMKt32h_1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# CLEANING TO COMPUTE EMBEDDINGS NOT NECESSARY IF WE ALREADY COMPUTED THEM\n",
        "df_train = df_train.dropna()\n",
        "df_train = df_train.reset_index(drop=True)\n",
        "\n",
        "df_train[\"question1\"] = df_train[\"question1\"].astype(\"str\")\n",
        "df_train[\"question2\"] = df_train[\"question2\"].astype('str')\n",
        "\n",
        "q1 = df_train['question1'].tolist()\n",
        "q2 = df_train['question2'].tolist()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sUL_PMZcP0gt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# OPTIONNAL\n",
        "df_test = df_test.dropna()\n",
        "df_test = df_test.reset_index(drop=True)\n",
        "\n",
        "df_test[\"question1\"] = df_test[\"question1\"].astype(\"str\")\n",
        "df_test[\"question2\"] = df_test[\"question2\"].astype('str')\n",
        "\n",
        "q1test = df_test['question1'].tolist()\n",
        "q2test = df_test['question2'].tolist()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zPlOpTbHzR11",
        "colab_type": "code",
        "outputId": "c4b766f3-4df3-4c5a-9ea4-ba04f013319a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 887
        }
      },
      "source": [
        "! pip install sentence-transformers"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting sentence-transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b9/46/b7d6c37d92d1bd65319220beabe4df845434930e3f30e42d3cfaecb74dc4/sentence-transformers-0.2.6.1.tar.gz (55kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 2.0MB/s \n",
            "\u001b[?25hCollecting transformers>=2.8.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a3/78/92cedda05552398352ed9784908b834ee32a0bd071a9b32de287327370b7/transformers-2.8.0-py3-none-any.whl (563kB)\n",
            "\u001b[K     |████████████████████████████████| 573kB 8.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from sentence-transformers) (4.38.0)\n",
            "Requirement already satisfied: torch>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from sentence-transformers) (1.5.0+cu101)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from sentence-transformers) (1.18.3)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from sentence-transformers) (0.22.2.post1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from sentence-transformers) (1.4.1)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.6/dist-packages (from sentence-transformers) (3.2.5)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers>=2.8.0->sentence-transformers) (2019.12.20)\n",
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/98/2c/8df20f3ac6c22ac224fff307ebc102818206c53fc454ecd37d8ac2060df5/sentencepiece-0.1.86-cp36-cp36m-manylinux1_x86_64.whl (1.0MB)\n",
            "\u001b[K     |████████████████████████████████| 1.0MB 64.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers>=2.8.0->sentence-transformers) (0.7)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers>=2.8.0->sentence-transformers) (2.21.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers>=2.8.0->sentence-transformers) (3.0.12)\n",
            "Collecting tokenizers==0.5.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d1/3f/73c881ea4723e43c1e9acf317cf407fab3a278daab3a69c98dcac511c04f/tokenizers-0.5.2-cp36-cp36m-manylinux1_x86_64.whl (3.7MB)\n",
            "\u001b[K     |████████████████████████████████| 3.7MB 42.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from transformers>=2.8.0->sentence-transformers) (1.12.46)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/99/50/93509f906a40bffd7d175f97fd75ea328ad9bd91f48f59c4bd084c94a25e/sacremoses-0.0.41.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 63.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch>=1.0.1->sentence-transformers) (0.16.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->sentence-transformers) (0.14.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from nltk->sentence-transformers) (1.12.0)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers>=2.8.0->sentence-transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers>=2.8.0->sentence-transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers>=2.8.0->sentence-transformers) (2020.4.5.1)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers>=2.8.0->sentence-transformers) (2.8)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers>=2.8.0->sentence-transformers) (0.3.3)\n",
            "Requirement already satisfied: botocore<1.16.0,>=1.15.46 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers>=2.8.0->sentence-transformers) (1.15.46)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers>=2.8.0->sentence-transformers) (0.9.5)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers>=2.8.0->sentence-transformers) (7.1.1)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.16.0,>=1.15.46->boto3->transformers>=2.8.0->sentence-transformers) (0.15.2)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.16.0,>=1.15.46->boto3->transformers>=2.8.0->sentence-transformers) (2.8.1)\n",
            "Building wheels for collected packages: sentence-transformers, sacremoses\n",
            "  Building wheel for sentence-transformers (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sentence-transformers: filename=sentence_transformers-0.2.6.1-cp36-none-any.whl size=74031 sha256=51dd340e6f1b022697a14355af42b3a5143dc138d2ab4ae9d5d0986bdf289b10\n",
            "  Stored in directory: /root/.cache/pip/wheels/d7/fa/17/2b081a8cd8b0a86753fb0e9826b3cc19f0207062c0b2da7008\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.41-cp36-none-any.whl size=893334 sha256=93345426d4ea0b8e6e8f4f3cd79b2cdcac5015457be6dc34c49db50152f5d844\n",
            "  Stored in directory: /root/.cache/pip/wheels/22/5a/d4/b020a81249de7dc63758a34222feaa668dbe8ebfe9170cc9b1\n",
            "Successfully built sentence-transformers sacremoses\n",
            "Installing collected packages: sentencepiece, tokenizers, sacremoses, transformers, sentence-transformers\n",
            "Successfully installed sacremoses-0.0.41 sentence-transformers-0.2.6.1 sentencepiece-0.1.86 tokenizers-0.5.2 transformers-2.8.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "90Khj5oozVvu",
        "colab_type": "code",
        "outputId": "39cc20bf-23be-4235-9cef-f284761fb5b2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "model = SentenceTransformer('bert-base-nli-mean-tokens')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 405M/405M [00:46<00:00, 8.74MB/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TV9rYak8XYJd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FHTOEPlaJZ-c",
        "colab_type": "code",
        "outputId": "a0b9b94c-2c04-4498-b42a-9f8e00bd1f58",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "### VECTORIZING QUESTIONS DF_TRAIN ###\n",
        "t1 = time.time()\n",
        "print(\"Computing embeddings for q1 train\")\n",
        "embq1 = model.encode(q1)\n",
        "t2 = time.time()-t1\n",
        "print(t2,\"seconds\", t2/60, \"minutes\" )\n",
        "\n",
        "t3 = time.time()\n",
        "print(\"Computing embeddings for q2 train \")\n",
        "embq2 = model.encode(q2)\n",
        "t4 = time.time()-t3\n",
        "print(t4,\"seconds\", t4/60, \"minutes\" )\n",
        "\n",
        "print('Total time',time.time()-t1,\"seconds\", (time.time()-t1)/60, \"minutes\" )"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Computing embeddings for q1 train\n",
            "561.5707659721375 seconds 9.359512766202291 minutes\n",
            "Computing embeddings for q2 train \n",
            "565.1609365940094 seconds 9.41934894323349 minutes\n",
            "Total time 1126.7327666282654 seconds 18.77887945175171 minutes\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hebXLEZ2XDx5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# save numpy array as csv file # NOT A GOOD IDEA\n",
        "from numpy import asarray\n",
        "from numpy import savetxt\n",
        "# define data\n",
        "embq1csv = asarray(embq1)\n",
        "embq2csv = asarray(embq2)\n",
        "# save to csv file\n",
        "savetxt('embq1.csv', embq1csv, delimiter=',')\n",
        "savetxt('embq2.csv', embq2csv, delimiter=',')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k2BcXbYkFYLH",
        "colab_type": "code",
        "outputId": "799bdcaf-30b0-40f1-c51c-62c1ad5fa5cf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "### VECTORIZING QUESTIONS DF_TEST ### OPTIONAL\n",
        "t1 = time.time()\n",
        "print(\"Computing embeddings for q1 test \")\n",
        "embq1test = model.encode(q1test[:100000])\n",
        "t2 = time.time()-t1\n",
        "print(t2,\"seconds\", t2/60, \"minutes\" )\n",
        "\n",
        "t3 = time.time()\n",
        "print(\"Computing embeddings for q2 test\")\n",
        "embq2test = model.encode(q2test[:100000])\n",
        "t4 = time.time()-t3\n",
        "print(t4,\"seconds\", t4/60, \"minutes\" )\n",
        "\n",
        "print('Total time',time.time()-t1,\"seconds\", (time.time()-t1)/60, \"minutes\" )"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Computing embeddings for q1 test \n",
            "138.44111609458923 seconds 2.3073519349098204 minutes\n",
            "Computing embeddings for q2 test\n",
            "138.17212510108948 seconds 2.3028687516848247 minutes\n",
            "Total time 276.6143307685852 seconds 4.6102388540903725 minutes\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qAKp8GZyP07_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_train['emb1'] = embq1\n",
        "df_train['emb2'] = embq2\n",
        "#df_test['emb1'] = embq1test\n",
        "#df_test['emb2'] = embq2test\n",
        "\n",
        "datatrain = df_train[:300000] \n",
        "datatest = df_train[300000:]\n",
        "datatest = datatest.reset_index(drop=True)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oANNw4QYGzDX",
        "colab_type": "code",
        "outputId": "5f40b8c3-1ea3-4f0d-c77a-98052b81d9c1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123
        }
      },
      "source": [
        "sim = []\n",
        "for i in range(datatrain.shape[0]):\n",
        "  if (i % 50000 == 0):\n",
        "    print(100 * i/datatrain.shape[0], \"% done\")\n",
        "  cosine = np.dot(embq1[i],embq2[i].transpose()) / (np.linalg.norm(embq1[i]) * np.linalg.norm(embq2[i]))\n",
        "  #sim.append(1/(1 + math.exp(-100*(cosine - 0.85))))\n",
        "  sim.append(cosine)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.0 % done\n",
            "16.666666666666668 % done\n",
            "33.333333333333336 % done\n",
            "50.0 % done\n",
            "66.66666666666667 % done\n",
            "83.33333333333333 % done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "necKjx7SNlM8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "th = []\n",
        "for i in range(200):\n",
        "  t = .8 + 0.001*i\n",
        "  dupl2 = (np.asarray(sim)>t)*1 \n",
        "  th.append(sum(datatrain['is_duplicate']== dupl2)/datatrain.shape[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v6pAm3xENnOe",
        "colab_type": "code",
        "outputId": "7599f338-3f07-4931-c3bd-81c8ff886eae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        }
      },
      "source": [
        "from matplotlib import pyplot as plt\n",
        "plt.plot(th)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7ff3124dafd0>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LvFzqZ3UO6Wx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Notes : avec embeddings pre trained 73 = pas mal \n",
        "# Tester les differents seuils peut s'apparenter a la phase de train. \n",
        "# Meilleure accuracy avec seuil de ~0.875 "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4sYlFcapGUa9",
        "colab_type": "code",
        "outputId": "3501e392-735d-4144-eb7b-7bc410db7d48",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 212
        }
      },
      "source": [
        "# TESTING \n",
        "simtest = []\n",
        "for i in range(datatest.shape[0]):\n",
        "  if (i % 10000 == 0):\n",
        "    print(100 * i/datatest.shape[0], \"% done\")\n",
        "  cosine = np.dot(datatest['emb1'][i],datatest['emb2'][i].transpose()) / (np.linalg.norm(datatest['emb1'][i]) * np.linalg.norm(datatest['emb2'][i]))\n",
        "  #sim.append(1/(1 + math.exp(-100*(cosine - 0.85))))\n",
        "  simtest.append(cosine)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.0 % done\n",
            "9.588922876293307 % done\n",
            "19.177845752586613 % done\n",
            "28.76676862887992 % done\n",
            "38.355691505173226 % done\n",
            "47.94461438146653 % done\n",
            "57.53353725775984 % done\n",
            "67.12246013405314 % done\n",
            "76.71138301034645 % done\n",
            "86.30030588663975 % done\n",
            "95.88922876293306 % done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n5w0vGZgGimy",
        "colab_type": "code",
        "outputId": "383247f7-d705-47bb-8d9b-00989859fcbf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "dupltest = (np.asarray(simtest)>0.875)*1 \n",
        "print(sum(datatest['is_duplicate']== dupltest)/datatest.shape[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.7307718124023128\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XBRNUdr_-DmF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchtext.data import Field, LabelField, TabularDataset, Iterator, BucketIterator\n",
        "from torchtext import vocab\n",
        "import torch.optim as optim"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hmuLuQx492Ve",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class siameseNet(nn.Module):\n",
        "  def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim):\n",
        "    super().__init__()\n",
        "    # self.embedding = nn.EmbeddingBag(vocab_size, embedding_dim, mode='mean')\n",
        "    #self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "    self.linear = nn.Linear(embedding_dim, hidden_dim)\n",
        "\n",
        "  def forward_one(self, x):\n",
        "    # output = self.embedding(x).mean(axis=0)\n",
        "    # output = nn.AdaptiveAvgPool1d(1)(output)\n",
        "    output = self.linear(x)\n",
        "    return output\n",
        "\n",
        "  def forward(self, input1, input2):\n",
        "    #emb1 = self.embedding(input1).mean(axis=0)\n",
        "    #emb2 = self.embedding(input2).mean(axis=0)\n",
        "    output1 = self.linear(input1)\n",
        "    output2 = self.linear(input2)\n",
        "    # output = torch.norm(output1-output2)\n",
        "    output = nn.CosineSimilarity()(output1, output2)\n",
        "    return output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wS_aUBmpxKRT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def train(model, vec1, vec2, optimizer, criterion, thresh, label, epoch):\n",
        "    # Track the loss\n",
        "    epoch_loss = 0\n",
        "    epoch_TP_FN = 0\n",
        "    epoch_FP_TN = 0\n",
        "    \n",
        "    model.train()\n",
        "    \n",
        "    for e in range(epoch):\n",
        "        print(\"Epoch {}/{}\".format(e,epoch))\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        predictions = model(vec1, vec2)\n",
        "        loss = criterion(predictions, label.type(torch.float) )\n",
        "        \n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        predicted_labels = predictions >= thresh\n",
        "        epoch_TP_FN += (predicted_labels==lab).sum().item()\n",
        "        epoch_FP_TN += (predicted_labels!=lab).sum().item()\n",
        "        \n",
        "        epoch_loss += loss.item()\n",
        "        print(epoch_TP_FN/(epoch_TP_FN+epoch_FP_TN))\n",
        "\n",
        "        \n",
        "    return epoch_loss / len(vec1), epoch_TP_FN/(epoch_TP_FN+epoch_FP_TN)\n",
        "\n",
        "\n",
        "def evaluate(model, v1, v2, criterion, thresh, label):\n",
        "    epoch_loss = 0\n",
        "    epoch_TP_FN = 0\n",
        "    epoch_FP_TN = 0\n",
        "    \n",
        "    model.eval()\n",
        "    \n",
        "    with torch.no_grad():\n",
        "          predictions = model(v1, v2)\n",
        "          loss = criterion(predictions, label.type(torch.float))\n",
        "\n",
        "          predicted_labels = predictions >= thresh\n",
        "          epoch_TP_FN += (predicted_labels==label).sum().item()\n",
        "          epoch_FP_TN += (predicted_labels!=label).sum().item()\n",
        "\n",
        "          epoch_loss += loss.item()\n",
        "          print(epoch_TP_FN/(epoch_TP_FN+epoch_FP_TN))\n",
        "      \n",
        "    return epoch_loss / len(v1), epoch_TP_FN/(epoch_TP_FN+epoch_FP_TN)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IYqCdUKM_uZE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = siameseNet(1,768,500,1)\n",
        "optimizer = optim.Adam(model.parameters())\n",
        "criterion = nn.BCEWithLogitsLoss()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fMyWG137_K3A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "v1 = torch.tensor(datatrain['emb1'])\n",
        "v2 = torch.tensor(datatrain['emb2'])\n",
        "lab = torch.tensor(datatrain['is_duplicate'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m9fI2j26Em8g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "v1test = torch.tensor(datatest['emb1'])\n",
        "v2test = torch.tensor(datatest['emb2'])\n",
        "labtest = torch.tensor(datatest['is_duplicate'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dyfB-4dB_ec-",
        "colab_type": "code",
        "outputId": "74726798-1b6d-4cce-af1c-ebe59bf743f1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        }
      },
      "source": [
        "train(model,v1,v2,optimizer,criterion, 0.8,lab,10)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0/10\n",
            "0.72265\n",
            "Epoch 1/10\n",
            "0.7226083333333333\n",
            "Epoch 2/10\n",
            "0.7225633333333333\n",
            "Epoch 3/10\n",
            "0.722545\n",
            "Epoch 4/10\n",
            "0.7225353333333333\n",
            "Epoch 5/10\n",
            "0.7225005555555556\n",
            "Epoch 6/10\n",
            "0.7224719047619048\n",
            "Epoch 7/10\n",
            "0.7224616666666667\n",
            "Epoch 8/10\n",
            "0.7224529629629629\n",
            "Epoch 9/10\n",
            "0.722469\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2.4509077668190003e-05, 0.722469)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qqfNnyVSB61U",
        "colab_type": "code",
        "outputId": "a3a7499e-1901-49d7-d43e-101d796fd567",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "evaluate(model, v1test, v2test, criterion, 0.75, labtest)\n"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.7252677706713205\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(7.081089182368325e-06, 0.7252677706713205)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MFeTvt97A8Qz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def linear_model_combined(optimizer='Adam'): \n",
        "    from keras.models import Model, Sequential\n",
        "    from keras.layers.core import Dense, Flatten, Activation, Dropout\n",
        "    from keras.layers import add\n",
        "\n",
        "    modela = Sequential()\n",
        "    modela.add(Flatten(input_shape=(1, 768)))\n",
        "    modela.add(Dense(1024))\n",
        "    modela.add(Activation('relu'))\n",
        "\n",
        "    modelb = Sequential()\n",
        "    modelb.add(Flatten(input_shape=(1, 768)))\n",
        "    modelb.add(Dense(1024))\n",
        "    modelb.add(Activation('relu'))\n",
        "\n",
        "\n",
        "    merged_output = add([modela.output, modelb.output])   \n",
        "\n",
        "    model_combined = Sequential()\n",
        "    model_combined.add(Activation('relu'))\n",
        "    model_combined.add(Dense(256))\n",
        "    model_combined.add(Activation('relu'))\n",
        "    model_combined.add(Dense(1))\n",
        "    model_combined.add(Activation('softmax'))\n",
        "\n",
        "    final_model = Model([modela.input, modelb.input], model_combined(merged_output))\n",
        "\n",
        "    final_model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
        "\n",
        "    return final_model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ygS9QvlgCoj0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mod = linear_model_combined()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L9OAoMUNCuoz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 532
        },
        "outputId": "a79504d0-94e7-4953-88bf-b6cfdf559282"
      },
      "source": [
        "mod.summary()"
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_4\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "flatten_3_input (InputLayer)    (None, 1, 768)       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "flatten_4_input (InputLayer)    (None, 1, 768)       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "flatten_3 (Flatten)             (None, 768)          0           flatten_3_input[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "flatten_4 (Flatten)             (None, 768)          0           flatten_4_input[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "dense_43 (Dense)                (None, 1024)         787456      flatten_3[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_44 (Dense)                (None, 1024)         787456      flatten_4[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 1024)         0           dense_43[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 1024)         0           dense_44[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_1 (Add)                     (None, 1024)         0           activation_3[0][0]               \n",
            "                                                                 activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "sequential_43 (Sequential)      (None, 1)            262657      add_1[0][0]                      \n",
            "==================================================================================================\n",
            "Total params: 1,837,569\n",
            "Trainable params: 1,837,569\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AcNoLf1rDMlk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import absolute_import\n",
        "from __future__ import print_function\n",
        "import numpy as np\n",
        "\n",
        "import random\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, Flatten, Dense, Dropout, Lambda\n",
        "from keras.optimizers import RMSprop\n",
        "from keras import backend as K\n",
        "epochs = 20\n",
        "\n",
        "\n",
        "\n",
        "def euclidean_distance(vects):\n",
        "    x, y = vects\n",
        "    sum_square = K.sum(K.square(x - y), axis=1, keepdims=True)\n",
        "    return K.sqrt(K.maximum(sum_square, K.epsilon()))\n",
        "\n",
        "\n",
        "def eucl_dist_output_shape(shapes):\n",
        "    shape1, shape2 = shapes\n",
        "    return (shape1[0], 1)\n",
        "\n",
        "\n",
        "def contrastive_loss(y_true, y_pred):\n",
        "    '''Contrastive loss from Hadsell-et-al.'06\n",
        "    http://yann.lecun.com/exdb/publis/pdf/hadsell-chopra-lecun-06.pdf\n",
        "    '''\n",
        "    margin = 1\n",
        "    square_pred = K.square(y_pred)\n",
        "    margin_square = K.square(K.maximum(margin - y_pred, 0))\n",
        "    return K.mean(y_true * square_pred + (1 - y_true) * margin_square)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def create_base_network(input_shape):\n",
        "    '''Base network to be shared (eq. to feature extraction).\n",
        "    '''\n",
        "    input = Input(input_shape)\n",
        "    x = Flatten()(input)\n",
        "    x = Dense(64, activation='relu')(x)\n",
        "    x = Dropout(0.1)(x)\n",
        "    x = Dense(64, activation='relu')(x)\n",
        "    return Model(input, x)\n",
        "\n",
        "\n",
        "def compute_accuracy(y_true, y_pred):\n",
        "    '''Compute classification accuracy with a fixed threshold on distances.\n",
        "    '''\n",
        "    pred = y_pred.ravel() < 0.5\n",
        "    return np.mean(pred == y_true)\n",
        "\n",
        "\n",
        "def accuracy(y_true, y_pred):\n",
        "    '''Compute classification accuracy with a fixed threshold on distances.\n",
        "    '''\n",
        "    return K.mean(K.equal(y_true, K.cast(y_pred < 0.5, y_true.dtype)))\n",
        "\n",
        "input_shape = (1,768,)\n",
        "\n",
        "# network definition\n",
        "base_network = create_base_network(input_shape)\n",
        "\n",
        "input_a = Input(input_shape)\n",
        "input_b = Input(input_shape)\n",
        "\n",
        "# because we re-use the same instance `base_network`,\n",
        "# the weights of the network\n",
        "# will be shared across the two branches\n",
        "processed_a = base_network(input_a)\n",
        "processed_b = base_network(input_b)\n",
        "\n",
        "distance = Lambda(euclidean_distance,\n",
        "                  output_shape=eucl_dist_output_shape)([processed_a, processed_b])\n",
        "\n",
        "model = Model([input_a, input_b], distance)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TzshypYyCzBY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 387
        },
        "outputId": "a46a9821-df7e-43c8-90f2-c4d08f07d161"
      },
      "source": [
        "v1 = np.asarray(v1)\n",
        "v2 = np.asarray(v2)\n",
        "lab = np.asarray(lab)\n",
        "# train\n",
        "rms = RMSprop()\n",
        "model.compile(loss=contrastive_loss, optimizer=rms, metrics=[accuracy])\n",
        "\n",
        "inp = np.stack((v1,v2))\n",
        "\n",
        "model.fit((inp[0], inp[1]), lab,\n",
        "          batch_size=128,\n",
        "          epochs=epochs)#,\n",
        "          #validation_data=([v1[1000:1100],v2[1000:1100]],lab[1000:1100]))\n",
        "\n",
        "# compute final accuracy on training and test sets\n",
        "y_pred = model.predict([tr_pairs[:, 0], tr_pairs[:, 1]])\n",
        "tr_acc = compute_accuracy(tr_y, y_pred)\n",
        "y_pred = model.predict([te_pairs[:, 0], te_pairs[:, 1]])\n",
        "te_acc = compute_accuracy(te_y, y_pred)\n",
        "\n",
        "print('* Accuracy on training set: %0.2f%%' % (100 * tr_acc))\n",
        "print('* Accuracy on test set: %0.2f%%' % (100 * te_acc))"
      ],
      "execution_count": 153,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-153-7f586ed3ce5f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m model.fit((inp[0], inp[1]), lab,\n\u001b[1;32m     11\u001b[0m           \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m           epochs=epochs)#,\n\u001b[0m\u001b[1;32m     13\u001b[0m           \u001b[0;31m#validation_data=([v1[1000:1100],v2[1000:1100]],lab[1000:1100]))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1152\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1153\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1154\u001b[0;31m             batch_size=batch_size)\n\u001b[0m\u001b[1;32m   1155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1156\u001b[0m         \u001b[0;31m# Prepare validation data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[1;32m    577\u001b[0m             \u001b[0mfeed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    578\u001b[0m             \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Don't enforce the batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 579\u001b[0;31m             exception_prefix='input')\n\u001b[0m\u001b[1;32m    580\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    581\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m     97\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'DataFrame'\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mstandardize_single_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_utils.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     97\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'DataFrame'\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mstandardize_single_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_single_array\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     32\u001b[0m                 'Got tensor with shape: %s' % str(shape))\n\u001b[1;32m     33\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m     \u001b[0;32melif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'ndim'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zu4xtHnTFXj9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "eeb33644-c736-4ea2-9cc4-ea3c0f4fba07"
      },
      "source": [
        "np.asarray(v1[:10]).shape"
      ],
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10, 768)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 118
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kBjMXqFKGQOm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "conc = np.concatenate((np.asarray(v1[:10]),(np.asarray(v2[:10]))), axis = 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "22dLIZj7GjKL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "conc = conc.reshape(10,2,768)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lz4nm4ZuHAPs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2a8e91d9-3679-4673-abe8-00ee27787b9d"
      },
      "source": [
        "conc[0].shape"
      ],
      "execution_count": 137,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2, 768)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 137
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U1gZPAVWHaNu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0ca2e8a6-f2de-413e-b92b-549911721447"
      },
      "source": [
        "v1.shape"
      ],
      "execution_count": 142,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(300000, 768)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 142
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P0gTbCZ1KXvf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "fe83ec2e-2517-485a-d0a3-d2524766a99b"
      },
      "source": [
        "v2.shape\n"
      ],
      "execution_count": 143,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(300000, 768)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 143
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bcItsCMdK2_i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
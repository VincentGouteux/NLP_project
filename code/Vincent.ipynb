{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Vincent.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "B1p1vckbjA0d",
        "colab_type": "code",
        "outputId": "dbd1722a-60a7-42e6-cade-026991f61f94",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        }
      },
      "source": [
        "# Mount drive\n",
        "import os\n",
        "from google.colab import drive\n",
        "%cd /content\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "%cd 'drive/My Drive/Colab Notebooks/NLP/project/code'\n",
        "%ls -l\n",
        "print(os.listdir())"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n",
            "Mounted at /content/drive\n",
            "/content/drive/My Drive/Colab Notebooks/NLP/project/code\n",
            "total 68\n",
            "-rw------- 1 root root  3534 Apr 22 16:32 cleaning.py\n",
            "-rw------- 1 root root 21800 Apr 25 09:06 pytorch_tuto.ipynb\n",
            "-rw------- 1 root root 22808 Apr 22 16:46 Untitled.ipynb\n",
            "-rw------- 1 root root  3545 Apr 22 16:32 utils_cleaning.py\n",
            "-rw------- 1 root root 16626 Apr 25 16:38 Vincent_w2v.ipynb\n",
            "['cleaning.py', 'utils_cleaning.py', 'Untitled.ipynb', '.ipynb_checkpoints', 'pytorch_tuto.ipynb', '.vector_cache', 'Vincent_w2v.ipynb']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mOP-tcvsiuig",
        "colab_type": "code",
        "outputId": "4c69a352-738e-4297-9e27-59811d5e6393",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "import re\n",
        "import time\n",
        "from string import punctuation\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# import nltk\n",
        "# from nltk.corpus import stopwords\n",
        "# nltk.download('stopwords')\n",
        "# from nltk.stem import SnowballStemmer\n",
        "# nltk.download('punkt')\n",
        "# from nltk.stem import WordNetLemmatizer \n",
        "# nltk.download('wordnet')\n",
        "\n",
        "# from gensim.test.utils import datapath, get_tmpfile\n",
        "# from gensim.models import KeyedVectors\n",
        "# from gensim.scripts.glove2word2vec import glove2word2vec\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchtext.data import Field, LabelField, TabularDataset, Iterator, BucketIterator\n",
        "from torchtext import vocab\n",
        "import torch.optim as optim"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QYJGX9FUMaJD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "EMBEDDING_PATH = '../data/embeddings/glove.6B.100d.txt'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cepvpo1mjUBg",
        "colab_type": "code",
        "outputId": "43881a78-1a41-4f2f-ebb1-f98ea26fbae9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "source": [
        "pd.read_csv(\"../data/train.csv\").head()"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>qid1</th>\n",
              "      <th>qid2</th>\n",
              "      <th>question1</th>\n",
              "      <th>question2</th>\n",
              "      <th>is_duplicate</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>What is the step by step guide to invest in sh...</td>\n",
              "      <td>What is the step by step guide to invest in sh...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>What is the story of Kohinoor (Koh-i-Noor) Dia...</td>\n",
              "      <td>What would happen if the Indian government sto...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>6</td>\n",
              "      <td>How can I increase the speed of my internet co...</td>\n",
              "      <td>How can Internet speed be increased by hacking...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>7</td>\n",
              "      <td>8</td>\n",
              "      <td>Why am I mentally very lonely? How can I solve...</td>\n",
              "      <td>Find the remainder when [math]23^{24}[/math] i...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>9</td>\n",
              "      <td>10</td>\n",
              "      <td>Which one dissolve in water quikly sugar, salt...</td>\n",
              "      <td>Which fish would survive in salt water?</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id  qid1  ...                                          question2 is_duplicate\n",
              "0   0     1  ...  What is the step by step guide to invest in sh...            0\n",
              "1   1     3  ...  What would happen if the Indian government sto...            0\n",
              "2   2     5  ...  How can Internet speed be increased by hacking...            0\n",
              "3   3     7  ...  Find the remainder when [math]23^{24}[/math] i...            0\n",
              "4   4     9  ...            Which fish would survive in salt water?            0\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HS8LKlwEnWAW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Preprocessing\n",
        "\n",
        "tokenize = lambda x: x.split()\n",
        "TEXT = Field(sequential=True, tokenize=tokenize, lower=True)\n",
        "LABEL = LabelField(dtype=torch.float)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hjVkbqgwnV7I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_datafields = [(\"id\", None),\n",
        "                 (\"qid1\", None),\n",
        "                 (\"qid2\", None),\n",
        "                 (\"question1\", TEXT),\n",
        "                 (\"question2\", TEXT),\n",
        "                 (\"is_duplicate\", LABEL)]\n",
        "\n",
        "test_datafields = [(\"id\", None),\n",
        "                   (\"question1\", TEXT),\n",
        "                   (\"question2\", TEXT)]\n",
        "\n",
        "# trn, vld = TabularDataset(\n",
        "#         path=\"../data/train.csv\",\n",
        "#         format='csv',\n",
        "#         skip_header=True, # if your csv header has a header, make sure to pass this to ensure it doesn't get proceesed as data!\n",
        "#         fields=tv_datafields\n",
        "#         ).split(\n",
        "#         split_ratio=0.7\n",
        "#         )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IoSUwbJRu0D4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "38a61cfa-fe5e-4226-cb15-f4e43d279966"
      },
      "source": [
        "train_data = TabularDataset(\n",
        "        path=\"../data/train.csv\",\n",
        "        format='csv',\n",
        "        skip_header=True, # if your csv header has a header, make sure to pass this to ensure it doesn't get proceesed as data!\n",
        "        fields=train_datafields\n",
        "        )\n",
        "\n",
        "# test_data = TabularDataset(\n",
        "#         path=\"../data/test.csv\",\n",
        "#         format='csv',\n",
        "#         skip_header=True, # if your csv header has a header, make sure to pass this to ensure it doesn't get proceesed as data!\n",
        "#         fields=test_datafields\n",
        "#         )\n",
        "\n",
        "train_data, valid_data = train_data.split(\n",
        "                  split_ratio=0.9,\n",
        "                  random_state=random.seed(42)\n",
        "                  )\n",
        "\n",
        "print(f'Number of training examples: {len(train_data)}')\n",
        "print(f'Number of validation examples: {len(valid_data)}')\n",
        "# print(f'Number of test examples: {len(test_data)}')"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of training examples: 363861\n",
            "Number of validation examples: 40429\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a6DgGJGBxZLv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vec = vocab.Vectors(EMBEDDING_PATH)\n",
        "\n",
        "TEXT.build_vocab(train_data, vectors = vec)\n",
        "LABEL.build_vocab(train_data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PPjgJmUUorrI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "outputId": "0432f927-9737-4005-960e-f419886fafcf"
      },
      "source": [
        "print(TEXT.vocab.freqs.most_common(10))\n",
        "print(train_data[0].question1, train_data[0].question2)\n",
        "print(valid_data[0].__dict__['question1'], valid_data[0].__dict__['question2'])\n",
        "print(len(TEXT.vocab))"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('the', 338525), ('what', 279949), ('is', 242034), ('how', 197011), ('i', 191790), ('a', 189350), ('to', 183554), ('in', 175138), ('of', 142965), ('do', 139198)]\n",
            "['how', 'do', 'i', 'loose', 'weight', 'fast?'] ['how', 'can', 'i', 'loose', 'weight', 'in', 'a', 'week?']\n",
            "['what', 'are', 'the', 'difference', 'between', 'share', 'and', 'equity?'] ['what', 'is', 'the', 'difference', 'between', 'a', 'stock,', 'a', 'share', 'and', 'an', 'equity?']\n",
            "189775\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7o-3FHq2qoBC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "# device='cpu'\n",
        "train_iter, valid_iter = BucketIterator.splits(\n",
        "        (train_data, valid_data), # we pass in the datasets we want the iterator to draw data from\n",
        "        batch_size=64,\n",
        "        device=device, # if you want to use the GPU, specify the GPU number here\n",
        "        sort_key=lambda x: len(x.question1)+len(x.question2), # the BucketIterator needs to be told what function it should use to group the data.\n",
        "        sort_within_batch=False\n",
        "        # repeat=False # we pass repeat=False because we want to wrap this Iterator layer.\n",
        ")\n",
        "\n",
        "# test_iter = Iterator(\n",
        "#     test,\n",
        "#     batch_size=64,\n",
        "#     device=device,\n",
        "#     train=False,\n",
        "#     sort=False,\n",
        "#     sort_within_batch=False\n",
        "# )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-aEHmC5NC_uA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# i=0\n",
        "# for batch in train_iter:\n",
        "#   print(batch)\n",
        "#   i+=1\n",
        "#   if i==5:\n",
        "#     break"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "576rFX6lqoIh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class siameseNet(nn.Module):\n",
        "  def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim):\n",
        "    super().__init__()\n",
        "    # self.embedding = nn.EmbeddingBag(vocab_size, embedding_dim, mode='mean')\n",
        "    self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "    self.linear = nn.Linear(embedding_dim, hidden_dim)\n",
        "\n",
        "  def forward_one(self, x):\n",
        "    output = self.embedding(x).mean(axis=0)\n",
        "    # output = nn.AdaptiveAvgPool1d(1)(output)\n",
        "    output = self.linear(output)\n",
        "    return output\n",
        "\n",
        "  def forward(self, input1, input2):\n",
        "    emb1 = self.embedding(input1).mean(axis=0)\n",
        "    emb2 = self.embedding(input2).mean(axis=0)\n",
        "    output1 = self.linear(emb1)\n",
        "    output2 = self.linear(emb2)\n",
        "    # output = torch.norm(output1-output2)\n",
        "    output = nn.CosineSimilarity()(output1, output2)\n",
        "    return output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n2uVtYix4mJ7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "emb_shape = TEXT.vocab.vectors.shape\n",
        "INPUT_DIM = emb_shape[0]\n",
        "EMBEDDING_DIM = emb_shape[1]\n",
        "HIDDEN_DIM = 50\n",
        "OUTPUT_DIM = 1\n",
        "\n",
        "model = siameseNet(vocab_size=INPUT_DIM, embedding_dim=EMBEDDING_DIM, hidden_dim=HIDDEN_DIM, output_dim=OUTPUT_DIM)\n",
        "\n",
        "pretrained_embeddings = TEXT.vocab.vectors\n",
        "# model.embedding.weight.data.copy_(pretrained_embeddings)\n",
        "model.embedding.from_pretrained(pretrained_embeddings, freeze=True)\n",
        "\n",
        "optimizer = optim.Adam(model.parameters())\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "# criterion = nn.BCELoss()\n",
        "\n",
        "model = model.to(device)\n",
        "criterion = criterion.to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q0PQXHq0611x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def compute_accuracy(predictions, labels, thresh=0.5):\n",
        "    predicted_labels = predictions >= thresh\n",
        "    accuracy = (predicted_labels == labels).sum()/len(predictions)\n",
        "    return accuracy.item()\n",
        "\n",
        "def train(model, iterator, optimizer, criterion, thresh=0.5):\n",
        "    # Track the loss\n",
        "    epoch_loss = 0\n",
        "    epoch_TP_FN = 0\n",
        "    epoch_FP_TN = 0\n",
        "    \n",
        "    model.train()\n",
        "    \n",
        "    for batch in iterator:\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        predictions = model(batch.question1, batch.question2)\n",
        "        loss = criterion(predictions, batch.is_duplicate)\n",
        "        \n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        predicted_labels = predictions >= thresh\n",
        "        epoch_TP_FN += (predicted_labels==batch.is_duplicate).sum().item()\n",
        "        epoch_FP_TN += (predicted_labels!=batch.is_duplicate).sum().item()\n",
        "        \n",
        "        epoch_loss += loss.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator), epoch_TP_FN/(epoch_TP_FN+epoch_FP_TN)\n",
        "\n",
        "\n",
        "def evaluate(model, iterator, criterion, thresh=0.5):\n",
        "    epoch_loss = 0\n",
        "    epoch_TP_FN = 0\n",
        "    epoch_FP_TN = 0\n",
        "    \n",
        "    model.eval()\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for batch in iterator:\n",
        "            predictions = model(batch.question1, batch.question2)\n",
        "            loss = criterion(predictions, batch.is_duplicate)\n",
        "\n",
        "            predicted_labels = predictions >= thresh\n",
        "            epoch_TP_FN += (predicted_labels==batch.is_duplicate).sum().item()\n",
        "            epoch_FP_TN += (predicted_labels!=batch.is_duplicate).sum().item()\n",
        "\n",
        "            epoch_loss += loss.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator), epoch_TP_FN/(epoch_TP_FN+epoch_FP_TN)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TMXFbWQV615H",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 410
        },
        "outputId": "de48c70b-7846-4717-8a8e-10660eca4f26"
      },
      "source": [
        "N_EPOCHS = 6\n",
        "\n",
        "# Track time taken\n",
        "start_time = time.time()\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "    epoch_start_time = time.time()\n",
        "    \n",
        "    train_loss, train_acc = train(model, train_iter, optimizer, criterion)\n",
        "    valid_loss, valid_acc = evaluate(model, valid_iter, criterion)\n",
        "    \n",
        "    print(f'| Epoch: {epoch+1:02} '\n",
        "          f'| Train Loss: {train_loss:.3f} '\n",
        "          f'| Train Accuracy: {train_acc:.3f} '\n",
        "          f'| Val. Loss: {valid_loss:.3f} '\n",
        "          f'| Val. Accuracy: {valid_acc:.3f} '\n",
        "          f'| Time taken: {time.time() - epoch_start_time:.2f}s'\n",
        "          f'| Time elapsed: {time.time() - start_time:.2f}s')"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "| Epoch: 01 | Train Loss: 0.719 | Train Accuracy: 0.683 | Val. Loss: 0.724 | Val. Accuracy: 0.687 | Time taken: 101.26s| Time elapsed: 101.26s\n",
            "| Epoch: 02 | Train Loss: 0.681 | Train Accuracy: 0.744 | Val. Loss: 0.702 | Val. Accuracy: 0.718 | Time taken: 101.83s| Time elapsed: 203.09s\n",
            "| Epoch: 03 | Train Loss: 0.649 | Train Accuracy: 0.782 | Val. Loss: 0.685 | Val. Accuracy: 0.729 | Time taken: 102.28s| Time elapsed: 305.37s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-86-b2431351648d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mepoch_start_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0mvalid_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-85-9bc5c460795a>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, iterator, optimizer, criterion, thresh)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mpredicted_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredictions\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mthresh\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0mepoch_TP_FN\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mpredicted_labels\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_duplicate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m         \u001b[0mepoch_FP_TN\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mpredicted_labels\u001b[0m\u001b[0;34m!=\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_duplicate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g35WNLgsNdxH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}